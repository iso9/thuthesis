
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:

\chapter{引言}
计算机从诞生那天起，就被赋予了辅助人类进行研究，生活与工作的使命。而在其发展过程中，人类一直是其模仿与超越的目标。与人类相比，计算机具有与生俱来的长处，例如擅长重复性的工作，对预先定义好的任务可以一丝不苟地完美完成，在纯粹的计算领域具有超越普通人的速度等。但同时，人类也有其不仅无法超越，甚至连接近都难以做到的地方，例如丰富的情感，创造性的思维以及对外界的认知与理解。这其中的难点在于人类本身对自己的这些能力也并没有深刻的理解，所以可以说计算机研究在这些领域的探索研究也代表了人类对自身奥秘的猜测与开发。这其中计算机视觉就是对人类视觉的一种理解，研究甚至超越。

计算机视觉的研究目标之一就是近似人类在视觉、认知上的能力，理解人脑的运行规律，最终得到超越人类极限的功能，从而代替人类进行更加危险，繁重的工作。而今，随着计算机硬件水平的提升，越来越多的图像视频设备的广泛应用，计算机视觉也成为备受人们关注的研究领域，吸引了生物，物理，数学等各个领域的研究者的目光。丰富多样的应用也逐渐出现在视频监控，人机交互，安全认证，图像处理，游戏娱乐等行业。然而，图像数据往往内容复杂，维数极高，而其中理解识别的对象又千变万化，完成鲁棒稳定有效的视觉技术都是极富挑战性的工作，具有高度的学术与应用价值。

在本章接下来的内容中，首先介绍本文研究的与人相关分割问题的背景，然后介绍图像分割问题的概念及分类，接下来分析本文研究的主要问题并介绍相关的工作，最后总结本文主要贡献并列出本文后续章节结构。
\section{研究背景}
近年来，随着手持摄影摄像设备的普及，视频监控摄像头的遍布，大量的图像视频数据产生出来，然而伴随这些数据而来的一个重要问题就是采用人工方式分析视频内容变得耗时耗力，甚至不可能完成。举个例子来说，在ImageNet\cite{imagenet}中，共有14,197,122张图片，21,841个可用描述词，假设每张图片只需要一个描述词进行描述（实际情况，往往需要多个描述词），每人1秒钟就可以选择到合适的描述，每天工作8小时，便需要将近一年半的时间才能完成这份工作，由此可见只是简单为图片选择一个描述词，在大数据量下已经变得如此繁重，更不用说定位物体位置，甚至更加复杂的物体形状的精确划定。这样的客观背景，使得视觉领域的应用变得愈加迫切，人们希望有技术能够帮助找到视频中出现的人并有效的跟踪其行动的路线，甚至对其诡异的行为能够自动报警；希望能有技术可以根据人本身的行为，表情，动作对设备进行随心所欲的操控；希望能有技术可以对自己拍摄的照片视频进行更加方便的编辑美化。在上述这些应用中，人往往作为人们关注的主体而存在，从而近十几年来一直到现在都仍是视觉领域的主要研究对象，也是本文所关注的研究对象。另外，这些客观需求，包含了对物体检测，物体跟踪，行为识别，物体精确分割等技术的要求，需要稳定可靠准确的技术满足人们的需要。

本文关注于其中的一个，也是视觉研究领域中一直以来的一个重要问题，图像分割。为什么需要图像分割的技术？这要从图像在计算机中的存在方式说起。不同于普通文本类信息，不管从何种设备中获取的图像视频文件都是采用特定的压缩，编解码方法存储在存储介质中。在计算机处理时，图像视频文件都是在像素级别上对其颜色进行描述。然而，需要特别注意的是，像素的概念并不是自然而然形成的，它并不是对自然界某种粒度单位的近似抽象，而是为了处理方便统一而人为定义的概念。这样就带来了一个问题，即对图像像素级别的描述，可能并不能准确的描述图像的内容，甚至可能都没有具体的意义，这在某些视频应用中，会带来困难与不便。

\begin{figure}[H] %
  \centering
  \includegraphics[width=0.7\textwidth]{segmentation_role.pdf}
  \caption{图像分割在视觉问题中的地位与相互关系}
  \label{fig:seg_role}
\end{figure}

为了解决这一问题，需要一些技术能够提供对图像内容更加符合自然界现象，或者更加接近人类感知的描述方法，而图像分割技术就应运而生。图像分割的基本目的就是将图像的像素点进行划分，得到若干更加准确有意义的区域。图像分割在视觉领域中占据了重要的位置，见~\ref{fig:seg_role}。粗略来讲，图像分割可以分为两大类，一类是超像素分割，一类是语义分割，二者不同点在于后者要求分割成的区域具有一定的语义含义，我们会在下一节中给出更加具体的介绍。一般而言，图像语义分割往往会用到超像素分割提供的信息，同时由于其对于图像内容的高层解读，故而往往也会利用物体检测，跟踪，识别的结果；另一方面，图像语义分割的结果也可以用来进一步增强或鉴别识别，检测等技术。而对图像的物体层的编辑、美化，对物体语义层以及形状的检索以及物体的三维建模的技术都直接或间接用到物体语义分割的结果。从这里可以看出，图像语义分割在视觉问题中占有重要地位，对它的研究一方面会促进对其他视觉问题的研究，另一方面也可以为新的应用提供更好的支持。

\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{study_scene.pdf}
  \caption{本文研究的典型场景与物体。其中(a)来自Labeled Faces in the Wild数据集~\cite{lfw}，(b)来自The Gallagher Collection Person数据集~\cite{cloth_coseg}，(c)来自TUD-Crossing视频~\cite{tud_crossing}}
  \label{fig:study_scene}
\end{figure}

而论及研究主体，人一直是视觉领域研究的核心之一。不论是人机交互，人脸检测/识别，乃至行人跟踪定位，突发事件检测等，对与人相关的问题一直遵循着由易至难，层层推进的方式不断发展完善。也因此，与人相关的若干技术，例如人脸检测\cite{hc_facedtection}，人体姿态识别\cite{kinect} 等都转化为成功的工业应用，从而具有高度的应用价值。然而，与人相关的分割问题在实际应用中，却仍然困难重重，挑战极大，这一方面是因为人体灵活多变，服饰颜色丰富，另一方面，实际应用中，背景嘈杂，光照也难以控制。鉴于此，本文将目标锁定在与人相关的语义分割中，但同时在算法设计与具体实现时，仍尽量保持其扩展性，以利于进一步应用到其他类型物体上。本文研究的主要场景与物体如图~\ref{fig:study_scene}所示，即单人图像中头肩区域分割（着重理解物体的内部结构，每个标签指代物体的不同部分，例如头发，人脸，衣服等），群体图像中衣服分割以及视频监控中拥挤场景的人体分割（着重理解人与人之间的关系，区分不同人物，每个标签指代一个人）。

\section{图像分割简介}
\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{sp_vs_semantic.pdf}
  \caption{超像素分割与语义分割的区别。(a)输入图片\cite{lfw}，(b)超像素JSEG\cite{jseg}分割结果，白色代表区域边界，(c)衣服分割结果\cite{whoblockswho}，其中不同颜色代表不同人。}
  \label{fig:sp_vs_semantic}
\end{figure}
图像分割粗略而言可以分为两类，一类是超像素分割，一类是语义分割。二者的共同之处都是将图像像素划分为不同区域，在新的尺度上描述图像内容；不同之处在于超像素分割并不要求分成的区域具有特定的语义含义，其算法一般通过优化底层特征的一致性，或启发式的具有宽泛指导意义的线索，而语义分割要求分割形成的区域具有特定的语义含义，这一类问题也可以成为图像标注，通常区域使用的标注词都是预先给定的，见图~\ref{fig:sp_vs_semantic}。二者分别在不同语义层次对图像内容进行划分，超像素分割更倾向于找到具有一般意义的图像单位，例如合适的区域，显著地边缘，有规律的纹理等；而语义分割则要求对图像内容给出特定概念的解释，例如行人，建筑，道路，草地，天空等。不过，它们并不是完全独立的，也有一些算法应用学习的知识学到比较高层的图像边缘，节点等特征，模糊了二者的中间地带。在实际应用中，语义分割往往要应用到超像素分割的结果。语义分割涉及到较为复杂的物体建模，表观分析，需要多种线索共同作用，超像素分割就是其中重要的一种。近年来，也有很多研究者致力于如何更好地将超像素分割的结果融入到语义分割中来~\cite{robustpn}\cite{hierarchicalcrf}\cite{dualdecomp}\cite{sparsehighorder}\cite{exacthighorder}。

\subsection{超像素分割}
图像分割是计算机视觉领域历史最悠久，研究最广泛的问题之一，早期的研究主要是超像素分割 ~\cite{brice1970scene}\cite{pavlidis1977structural}\cite{riseman1977computational}\cite{ohlander1978picture}\cite{rosenfeld1979image}\cite{haralick1985image}。 初期采用的技术倾向于区域分裂和增长~\cite{brice1970scene}\cite{horowitz1976picture}\cite{ohlander1978picture}\cite{pavlidis1990integrating}\cite{jseg}。 之后随着优化领域研究的发展及引入，越来越多的技术是通过优化某个全局目标来得到连通的区域，例如最大化区域内的相似性，最大化区域间的差异等~\cite{leclerc1989constructing}\cite{mumford1985boundary}\cite{ncut}\cite{meanshift}\cite{graphseg}\cite{levelset}。 近年来随着统计学习方法的兴起及其在数据挖掘，自然语言处理等领域的成功应用，一批基于学习的图像分割技术也表现出良好的性能~\cite{ren2008multi}\cite{xiaofeng2012discriminatively}\cite{dollar2006supervised}\cite{hariharan2011semantic}。 可见图像超像素分割算法不胜枚举，为定量客观的衡量超像素分割的性能，一些由人标注的用于验证分割性能的数据集被提出来，其中最著名是Berkeley Segmentation Dataset and Benchmark~\cite{berkeleyseg}。另外，Alpert, Galun等也提出了新的数据集~\cite{alpert2007image}用于图像分割性能评测。
\begin{figure}[H]
  \centering
  \includegraphics[width=0.7\textwidth]{sp.pdf}
  \caption{四种超像素分割结果}
  \label{fig:sp}
\end{figure}

鉴于超像素分割算法种类繁多，本文并不一一列举，在本节中仅简要介绍本文以及视觉研究中经常用到的几种算法。视觉中应用最多的超像素分割算法之一是规范图割方法(Normalized Cut)~\cite{ncut}。它将图像看做图(Graph)，同时优化类间不相似性以及类内相似性，克服了基于最小割只利用类间不相似性算法容易生成不匀称区域的问题。Shi和Malik也提出了基于扩展特征值问题的优化算法，使得计算更加高效。另外一个被广泛应用的算法是均值移位(Mean Shift)~\cite{meanshift}方法，它实际上是对特征空间的一种分析，采用均值移位的方法寻找数据概率密度分布的局部最大值。在应用于图像分割时，将像素点之间的差别用来定义密度，从而找到合适的超像素分割结果。这两种算法都建立了一个全局的优化目标，而后针对自己的目标采用不同的优化策略进行优化得到最终的分割结果。在本文中，我们还使用了其他两种算法，一种是JSEG~\cite{jseg}，该算法是基于区域生长的分割算法，其不同之处在于进行区域生长之前，对图像根据颜色纹理进行了量化，之而在量化后的图像上进行生长，其结果更加鲁棒；另一种方法是SLIC~\cite{slic}，该算法是通过聚类的方式，对像素点进行划分，其最大的优势是速度快，可以做到实时，在进行视频处理时非常有效。这几种算法的示意结果如图~\ref{fig:sp}所示。需要注意的是，在实际应用中，往往并不容易确定哪一种超像素分割最适合该问题，需要通过实验来验证。

\subsection{语义分割}
\begin{figure}[H]
  \centering
  \includegraphics[width=\textwidth]{semantic_seg_framework.pdf}
  \caption{一般语义分割算法框架}
  \label{fig:semantic_seg_framework}
\end{figure}

随着超像素分割的逐步发展，渐渐研究者不再满足于对图像的低层划分，而希望能够直接获得语义层次上的解析，图像语义分割逐渐崭露头角。语义分割要求在输入图像的基础上，获得图像中人们感兴趣的语义物体形状。这通常涉及到大量线索，包括物体的检测，形状建模，表观建模，超像素约束等；同时为了整合这些线索，又会引入复杂的模型，例如概率图模型，从而涉及到图模型推理以及结构、参数学习等工作。我们在图~\ref{fig:semantic_seg_framework}中给出一般意义下图像语义分割的框架。语义分割涉及到特定类的物体，一般需要一定量的训练数据，其中图像进行像素级别的标注，也有一些算法采用弱标注(Weakly-Labeled Data)和半标注(Semi-Labeled Data)进行训练学习。分割的结果是物体的准确位置以及形状，所以一般会需要物体定位算法。这里需要注意的是，有些物体的定位是通过其他算法得到（例如本文中的人脸以及行人检测），而有一些语义分割算法本身也会进行物体的定位。同时为了更加精确的刻画物体形状，需要多种线索共同作用，包括形状模型，表观模型，超像素约束，上下文信息(Context Information)以及其他启发式信息。目前使用较多的线索融合方式是概率图模型，而随着图模型相关推理，参数学习算法的发展，在语义分割中一般也会涉及到参数，甚至结构学习的算法。最后为了得到最终的分割结果，需要对图模型进行推理。由于任意图模型的推理是不可解问题，已有算法都对模型中能量函数定义，图结构有不同的约束，而这经常会与多线索融合产生矛盾。这种情况下需要对经典的推理算法进行调整，甚至重新设计推理算法。在图~\ref{fig:semantic_seg_framework}中红色标注的部分是本文涉及到的内容。一个完整的语义分割算法，是包含了多种信息的综合框架，而研究者在其中各个方面都做出不同的贡献。为了更好的介绍相关的工作，在接下来的内容，本文将分别从分割对象，线索信息，推理，学习等方面对已有工作进行归纳总结。

首先，如何确定语义物体位置。定位物体是语义分割的起点，在很大程度上影响分割的准确性。不同方法采用不同的定位策略，但大略有以下规律。根据分割应用的问题，大略可以分为两类：一类是场景标注，一类是特定物体分割。一般认为，语义分割的对象包括两种~\cite{thingstuff}\cite{forsyth1996finding}：材料(Stuff/materials) 和物体（Things/objects）。材料为各向同质的或具有重复性模式，但没有特定的空间方位和形状；而物体具有特定的大小与形状，例如天空，草地，道路等都可以认为是材料，而汽车，行人，动物等都可以认为是物体。场景标注类问题要求对场景中所有物体，材料都进行标注，完成对整个场景的分析；而特定物体分割类问题，要求对场景中出现的所有特定类物体（一般不是材料） 进行分割。场景标注类方法综合多种特征（纹理，SIFT~\cite{sift}，GIST\cite{gist}，颜色等），建立多类别物体的分类器\cite{textonboost}\cite{stf}\cite{structrf}。这些算法本身可以对图像进行像素级别的分类，但往往失于粗糙，并不能给出准确的边界，需要更多信息的辅助，但可以作为其他算法的基石与起点。而特定物体分割问题针对的一般是较为常见的物体，例如汽车，行人，动物等，部分算法~\cite{whoblockswho}\cite{goodparts}\cite{lvlsetseg}采用较为成熟的检测算法~\cite{vjdetect}\cite{hog}\cite{houghforest}，部分算法~\cite{objcut}\cite{aeembed}\cite{layeredobject} 根据已有的检测算法框架~\cite{dpm}\cite{poselet}\cite{ps}重新训练并嵌入分割算法中，还有部分算法采用自行定义的物体检测分割模型~\cite{shapeguided}\cite{learn2combine}\cite{tdbu}\cite{recursiveseg} （一般同时包含检测与分割信息）。 除此之外，还有一类问题称为显著物体检测（Salient Object Detection）定位图片中显著的物体，该类算法~\cite{salient1}\cite{salient2}\cite{salient3}\cite{salient4} 也会提供物体定位与粗分割的结果，但一般没有强的语义含义，只是保证所得区域为在人视觉中主导的区域。

其次，需要引入哪些特征。在有了物体初定位的条件下，需要更多的信息来寻找物体准确的边界。采用的特征范围极广，从底层的图像特征，到高层的语义层，认知层的特征都有涉及。在介绍涉及的特征之前，我们要给出一个函数的阶（Order）的概念，通俗的讲，它指的是该函数涉及到的不同自变量的个数。我们在之后的章节中会有更加正式的说明。这个概念在这里的作用就是帮助理解特征的复杂程度。阶数越高，特征越复杂，描述能力越强，但同时其计算负担也就越重，甚至可能令优化变得不可能。下面详细介绍分割中用到的不同特征。首先利用到的就是前面所说的物体定位特征，该特征基本确定了物体的大概位置，有时甚至粗略描述了物体形状，所以在特征中占据主导地位。其次，引入的包括纹理特征~\cite{objcut}，颜色特征~\cite{textonboost}\cite{whoblockswho}\cite{goodparts}\cite{layeredobject}，位置特征~\cite{textonboost}\cite{whoblockswho}\cite{goodparts}，形状特征~\cite{layeredobject}\cite{whoblockswho}\cite{goodparts}等，这些特征从图片底层获得，较为简单，也较易于融合到分割框架中，例如在基于马尔科夫随机场与条件随机场的框架中，该类特征以一阶势函数形势加入其中。而基于随机场的优化算法对一阶势函数没有约束，这也使得这一类特征具有较高灵活性的同时，也无需担心算法的推理及优化过程。第三，引入梯度特征，用以刻画物体边界特征，其基本想法是如果相邻节点（像素，超像素等）使用了不同标签（即隶属于不同语义概念），则二者颜色差异越大，其势函数能量越小。该特征在基于随机场的框架中应用广泛，由上面描述可见，该特征涉及相邻两个像素，属于二阶特征，一般采用对比敏感的Potts模型（Contrast Sensitive Potts Model）~\cite{pottsmodel}，因为Potts模型满足子模特性（Submodularity）从而可以有效采用基于最小图割（Min-Cut）的优化算法~\cite{fastgc}\cite{expmincut}\cite{whatenergy}求解。第四，能量最小化的Potts模型最优解有最短边界倾向，受其影响，对于复杂边缘的物体无法刻画。二阶特征已经难以满足对于精度的要求，就有更多的算法加入了三阶乃至更高阶的特征。那么哪些自变量（像素点）应该放在一起呢？一个最自然的想法就是由超像素分割算法产生的超像素，并在超像素的基础上定义特征~\cite{robusthighorder}\cite{hierarchicalcrf}\cite{stackedlabel}\cite{harmonypot}。 其基本思想是希望同一个超像素内的像素都采用同样的语义标签，然而如果只是简单的达到这个目标，并不需要复杂的算法，只需要将分割算法定义到超像素上即可\cite{layeredobject}\cite{classaffinity}。但超像素并不总是刻画物体的语义边界，只是在超像素层上定义分割，无法避免由于超像素本身带来的分割错误。为了解决这一点，就将超像素作为高阶软约束（Higher Order Soft Constraints）引入，即希望超像素内的像素都采用同一个语义标签，如果不同则按情况给出惩罚。另外，还有一些方法采用多种不同超像素结果~\cite{hierarchicalcrf}\cite{stackedlabel}作为约束来提升分割准确性。需要注意的是，采用超像素级高阶约束，往往会给模型推理，能量优化带来困难，需要新的推理算法。最后，之前各类特征都是底层特征，并不包含对场景，对物体本身的理解，进一步为了得到更好的分割效果，越来越多的高层语义特征引入其中，这些特征代表了对于该问题的认知，或者从数据中总结出来的信息，可以统一称之为先验知识。此类特征往往因问题而异，例如根据训练集统计得到的不同物体出现在同一图片概率的约束~\cite{cooccur}；限定不同部件之间布局顺序的约束~\cite{layoutcrf}，限制出现在同一图片中标签种类的约束\cite{labelcost}；要求不同语义标签具有一定几何顺序的约束~\cite{labelorder}；包含同一物体的不同图片分割前景一致性的约束~\cite{multicoseg}\cite{objcoseg}等；对于分割得到物体拓扑特征的约束~\cite{topocut}；对于某些物体可以预知大小的约束~\cite{labelcount}；对于物体已知其颜色分布的约束\cite{distcut} 等。这一类约束一定程度上弥补了马尔科夫随机场难以模型化全局信息的缺点，但他们更加复杂，经常是对整张图片性质的统计，故而其设计需要更加谨慎，而推理以及优化需要单独考虑。

第三，如何对模型进行推理。主流的分割算法都是以概率图模型为框架融合多种特征。一般而言，都是采用无向图对分割建模，个别论文~\cite{unifiedgm}也会引入有向边来描述图像中具有因果关系的要素，构成有向图与无向图的混合图对图像进行分割。在最差情况下，任意无向图的推理是NP- 难问题，甚至近似推理都是NP-难问题~\cite{kollerpgm}。但幸运的是，大部分实际中遇到的问题都可以非常有效的进行准确推理或近似推理。关于无向图推理的算法非常多，这里并不一一列举，只是指出在视觉问题中经常用到的几种算法：一类是基于置信度传播（Belief Propagation）~\cite{bp}的算法，包括Loopy Belief Propagation，Generalized Belief Propagation~\cite{gbp}，Gaussian Belief Propagation~\cite{gaussianbp}等。Belief Propagation对于单连接图可以到准确的推理结果，但对于有环的图并不能保证结果的正确性，甚至可能连是否近似都不能保证~\cite{emplbp}。但实践中，Loopy Belief Propagation往往可以给出较为满意的结果，而又由于它对于能量函数的定义并没有约束，故而也常常被应用在实际中。一类是基于最小图割（Min-Cut）的算法，包括专门针对于视觉领域实现的最大流算法~\cite{expmincut}，用以处理多标签标注问题的alpha-expansiaon/alpha-beta-swap算法~\cite{expmincut}\cite{whatenergy}\cite{fastgc}，以及用以推理具有大规模节点图的算法~\cite{scalablegc}。基于最小图割的算法在分割类问题中被广泛应用，因为分割类问题所建立的图模型成环现象非常严重，导致基于Belief Propagation的算法准确度无法保证，而基于最小图割的算法在二值标签且能量函数满足子模特性（Submodularity）~\cite{whatenergy}时可以有效的得到准确解。在最小图割算法的基础上，为了处理不同特征引入带来的复杂势函数，大量独特设计的算法被进一步提出，例如处理超像素约束引入的高阶势函数的算法~\cite{robusthighorder}，引入物体连通性约束的~\cite{topocut}\cite{conncut}等。这些算法往往需要精巧的势函数设计与高超的算法设计技巧，也就限制了他们在更广泛推理问题上的应用，故而，近年来还有一类基于对偶分解（Dual Decomposition）~\cite{dualdecomp}的推理框架逐渐被人们所重视。他们将原本不可解的图推理问题，分解为若干有已知算法可解的问题进行求解，再将子问题的解通过有原则的方式进行组合，不断迭代该过程，直至收敛。可以看出来，对偶分解提供了一种优化的框架，而其优势在于该框架具有非常高的一般性与扩展性，使得其应用非常广泛~\cite{conncut}\cite{beyondpw}\cite{beyondlp}\cite{jointsegapp}。最后，还有一类算法将能量函数转化为二次伪二值函数进行优化~\cite{sparsehighorder}\cite{cliqueqpbf}\cite{exacthighorder}\cite{branchmincut}，限于篇幅，且在本文中未曾涉及，这里就不再进行详细介绍。

\begin{table}[h]
\centering
\begin{minipage}[t]{0.9\linewidth}
  \caption{关于分割问题的研究分类}
  \label{tab:seg_research}
  \begin{tabular*}{\linewidth}{p{2cm}|p{3.5cm}|p{6.7cm}}
  \toprule[1.5pt]
  研究问题 & 分类 & 代表方法 \\
  \hline
  \hline
  \multirow{2}{*}{物体定位} & 场景标注 & 基于纹理以及上下文特征等的多物体分类\\ \cline{2-3}
   & 特定物体分割 & 基于检测，基于已有框架，融合分割与检测等 \\
  \hline
  \hline
  \multirow{4}{*}{融合线索} & 一阶势函数 & 形状，位置，颜色特征 \\ \cline{2-3}
   & 二阶势函数 & 梯度，部件顺序~\cite{layoutcrf} \\ \cline{2-3}
   & 高阶势函数 & 超像素约束 \\ \cline{2-3}
   & 高层信息 & 标签，颜色，拓扑等全局约束 \\
  \hline
  \hline
  \multirow{3}{*}{推理方法} & 基于置信度传播~\cite{bp} & Generalized BP 等 \\ \cline{2-3}
  & 基于最小图割~\cite{fastgc} & $\alpha$-expansion等 \\ \cline{2-3}
  & 基于对偶分解~\cite{dualdecomp} & 参见相关论文~\cite{conncut}\cite{beyondpw}\cite{beyondlp}\cite{jointsegapp} \\
  \hline
  \hline
  \multirow{1}{*}{结构学习} & 约束结构搜索空间 & 基于树形结构，基于启发式搜索\\ \cline{2-3}
  \hline
  \hline
  \multirow{2}{*}{参数学习} & 基于最大化似然估计 & 分段优化，伪似然函数 \\ \cline{2-3}
  & 基于最大化间隔 & 结构SVM，最大间隔马尔科夫网 \\
  \bottomrule[1.5pt]
  \end{tabular*}
\end{minipage}
\end{table}

最后，如何对模型进行学习。概率图模型的学习包括两个方面，结构学习与参数学习。结构学习指的是确定图中关联的边，即哪些变量之间存在依赖关系，而参数学习指的是确定能量方程中，各个势函数的权重。一般而言，结构学习是更加困难的问题，有的会加入较强的约束，例如假设图具有树状结构~\cite{treestruct}，或采用启发式搜索的方法~\cite{mutualcontext}。但一般而言，在分割中，结构学习并不多见，因为图像中的像素与超像素本身具有较为自然的结构定义规律，例如四邻域，邻接区域等。而参数学习方面，根据优化目标不同，有不同的算法。一类算法是采用最大似然估计法（Maximum Likelihood Estimation，简写为MLE）。在较为复杂的方法中，似然函数（Likelihood Function）往往不是凸的，不能直接使用牛顿迭代等优化算法。为此，部分论文~\cite{robusthighorder}\cite{textonboost} 采用分段学习~\cite{piecewisetrain} 的方法，分段学习的方法分为两步，首先将原图分解为不连通的子图，对每个子图进行训练，之后学习到的权重混合起来，不同子图在联合训练。分段学习是非常高效的学习方式，也被广泛应用，但到目前为止，对其在准确度方面的损失有清晰地估计。另有一部分论文~\cite{dtf}\cite{rtf}使用伪似然函数~\cite{pseudolikelihood}来近似原始似然函数。相较原始似然函数，伪似然函数可以使得计算更加快速遍历，从而加速训练过程。另一类优化算法的目标是在分类器以及检测方面被广泛应用的最大化间隔（Max Margin）类算法。不同于一般的分类检测算法，在分割类问题上，其输出并非二值或者若干值，而往往是非常多的输出变量，变量之间又存在着复杂的依赖关系，原始的最大化间隔类算法不能解决此类问题。近年来随着结构化最大间隔类学习算法~\cite{structuredsvm}\cite{m3n}\cite{approxtrain}\cite{lsvm}\cite{gclearn} 的兴起与成功应用，这些算法越来越受到人们的关注，而被应用到分割问题~\cite{svmseg1}\cite{gclearn}\cite{svmseg2}\cite{svmseg3}中。

总结一下，在表~\ref{tab:seg_research}中，我们列出了跟分割相关的各种研究方向以及相关的经典方法。

\section{本文研究问题分析}
本文关注于与人相关的图像语义分割，其基本研究场景如图~\ref{fig:study_scene}所示。我们将针对单人头发分割，多人衣服及行人分割，和半监督指导下的分割进行探讨。这些算法的核心都在于，给定一定的训练集（在半监督分割中还包含同源的未标注数据），如何从中学习到合适的物体模型，能够清晰准确鲁棒的表达物体形状，表观等，并且尽量保证算法在复杂的背景与光照条件下，都保持较高的准确度。本文从特征提取，模型建模，参数学习，模型推理等方面对这些问题进行了详尽而深入的探讨，分析了不同问题中面对的主要困难，研究可能的解决方案，进而期望能够对面向人的分割问题有一个全面而深入的了解。
\section{本文主要贡献以及章节结构}


